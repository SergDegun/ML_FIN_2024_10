{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install backtrader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qwxdicmlcox3",
        "outputId": "5b3ac61d-341c-4c7e-f75f-fc319eed1e92"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting backtrader\n",
            "  Downloading backtrader-1.9.78.123-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading backtrader-1.9.78.123-py2.py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.5/419.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: backtrader\n",
            "Successfully installed backtrader-1.9.78.123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install gensim"
      ],
      "metadata": {
        "id": "8HTfgUyXd-QU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QOLTvGmPZ14W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "import backtrader as bt\n",
        "#from gensim.models import KeyedVectors\n",
        "#from gensim.matutils import unitvec\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "from collections import Counter, defaultdict\n",
        "from scipy.linalg import eigh\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Strategy parameters\n",
        "s_ticker = \"AAPL\"\n",
        "s_start_date = \"1990-01-01\"\n",
        "s_end_date = \"2025-04-08\"\n",
        "i_start_capital = 1\n",
        "d_trader_marging = 0.0005\n",
        "i_test_trend_size = 250\n",
        "i_window_size = 4\n",
        "i_predict_amount = 1\n",
        "i_buffer_size = 9\n",
        "i_ranges_amount = 5\n",
        "i_amount_excluded = 6\n",
        "i_polinom_order_model = 1\n",
        "b_is_using_const_model = True\n",
        "d_rmse_koef = 3.0\n",
        "d_probably_min = 1e-10\n",
        "i_density_amount = 10\n",
        "d_order_softmax_out = 3\n",
        "b_is_short_enabled = False\n",
        "d_zero_zone_koef = 0.01\n",
        "d_trend_koef_up = 0.001\n",
        "d_trend_koef_dn = 0.001\n",
        "d_dither_koef = 0.7"
      ],
      "metadata": {
        "id": "CdFTudG0YbBY"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных из файла\n",
        "def load_data_from_file(file_path):\n",
        "  try:\n",
        "    data = pd.read_csv(file_path)\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    data.set_index('Date', inplace=True)\n",
        "    return data\n",
        "  except FileNotFoundError:\n",
        "      print(f\"Файл '{file_path}' не найден.\")\n",
        "      return None\n",
        "\n",
        "# Загрузка данных из yaho finance\n",
        "def load_data_from_yf(ticker, timeframe='1d'):\n",
        "  df = yf.download(ticker, interval=timeframe)\n",
        "  df = df.reset_index()\n",
        "  if isinstance(df.columns, pd.MultiIndex):\n",
        "      df.columns = df.columns.droplevel(level=1)\n",
        "  df['Date'] = pd.to_datetime(df['Date'])\n",
        "  df.set_index('Date', inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "WL8Li0kTHLjD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных из файла\n",
        "file_path = 'SBER_231007.csv'  # Замените на путь к вашему файлу\n",
        "data = load_data_from_file(file_path)\n",
        "# Load data using yfinance\n",
        "# data = yf.download(s_ticker, start=s_start_date, end=s_end_date)\n",
        "#data = load_data_from_yf(s_ticker)\n",
        "if data.empty:\n",
        "    raise ValueError(\"No data downloaded for the given ticker and date range\")"
      ],
      "metadata": {
        "id": "RgUAMzC0zzlC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Добавление новых признаков\n",
        "data['Mean'] = (data['Open'] + data['High'] + data['Low'] + data['Close']) / 4  # Средняя цена\n",
        "data['Value'] = data['Volume'] * data['Mean']  # Объём в деньгах\n",
        "# Prepare trend data\n",
        "p_trend_mean = data['Mean'].values\n",
        "p_trend_open = data['Open'].values\n",
        "p_trend_hi = data['High'].values\n",
        "p_trend_lo = data['Low'].values\n",
        "p_trend_close = data['Close'].values\n",
        "p_trend_volume = data['Volume'].values\n",
        "p_trend_value = data['Value'].values"
      ],
      "metadata": {
        "id": "ncDzVri8ef9O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Length of trend for training\n",
        "i_prep_trend_length = max(len(p_trend_mean) - i_test_trend_size, 0)"
      ],
      "metadata": {
        "id": "W2m9pa4V0MZx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization function\n",
        "def norming_e(p_trend, i_target_position, i_vector_size, i_samples_pos, i_amount_samples, b_is_minus_offset):\n",
        "    p_result_vector = np.zeros(i_vector_size)\n",
        "    d_e = np.mean(p_trend[i_target_position - i_vector_size + i_samples_pos :\n",
        "                          i_target_position - i_vector_size + i_samples_pos + i_amount_samples])\n",
        "    d_offset = 1 if b_is_minus_offset else 0\n",
        "    p_result_vector = (p_trend[i_target_position - i_vector_size : i_target_position] / d_e) - d_offset\n",
        "    return p_result_vector"
      ],
      "metadata": {
        "id": "sulZT2YV0dP5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate dot product of two vectors\n",
        "def get_multip(vector1: np.ndarray, vector2: np.ndarray, i_vector_size: int) -> float:\n",
        "    return np.dot(vector1[-i_vector_size:], vector2[-i_vector_size:])"
      ],
      "metadata": {
        "id": "wu-TmbuE3fNv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate covariance matrix\n",
        "def kovariation_matrix(trends: List[np.ndarray], matrix_size: int) -> np.ndarray:\n",
        "    kov = np.zeros((matrix_size, matrix_size))\n",
        "    e = np.zeros(matrix_size)\n",
        "    i_trend_cols = 0\n",
        "\n",
        "    for d_line in trends:\n",
        "        if d_line is None:\n",
        "            continue\n",
        "\n",
        "        i_trend_cols += 1\n",
        "        for i1 in range(matrix_size):\n",
        "            d_tmp1 = d_line[i1]\n",
        "            e[i1] += d_tmp1\n",
        "            for i2 in range(i1, matrix_size):\n",
        "                d_tmp2 = d_line[i2]\n",
        "                kov[i1, i2] += (d_tmp1 * d_tmp2)\n",
        "\n",
        "    e /= i_trend_cols\n",
        "    for i1 in range(matrix_size):\n",
        "        d_tmp1 = e[i1]\n",
        "        for i2 in range(i1, matrix_size):\n",
        "            d_tmp2 = e[i2]\n",
        "            kov[i1, i2] = ((kov[i1, i2] / i_trend_cols) - (d_tmp1 * d_tmp2))\n",
        "            kov[i2, i1] = kov[i1, i2]\n",
        "\n",
        "    return kov"
      ],
      "metadata": {
        "id": "_y6G2KPg4Axj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find eigenvectors of symmetric matrix\n",
        "def get_optim_matrix_by_kov(kov: np.ndarray, i_matrix_size: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    # Get sum of diagonal elements of covariance matrix\n",
        "    d_norma_vals = np.trace(kov)\n",
        "    if d_norma_vals == 0:\n",
        "        # Covariance matrix is degenerate\n",
        "        return None, None\n",
        "\n",
        "    # Find eigenmatrix\n",
        "    try:\n",
        "        params, v = eigh(kov)\n",
        "    except Exception as e:\n",
        "        print(f\"Error finding eigenvectors: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Check and normalize eigenvalues of covariance matrix\n",
        "    params /= d_norma_vals\n",
        "    if np.sum(params) == 0:\n",
        "        return None, None\n",
        "\n",
        "    # Copy values to matrix\n",
        "    res_matrix = np.zeros((i_matrix_size, i_matrix_size))\n",
        "    for w in range(i_matrix_size):\n",
        "        i_multi = 1 if v[0, w] > 0 else -1\n",
        "        for i in range(i_matrix_size):\n",
        "            res_matrix[w, i] = i_multi * v[i, w]\n",
        "\n",
        "    # Sort matrix rows in descending order of eigenvalues\n",
        "    sorted_indices = np.argsort(-np.abs(params))\n",
        "    params = params[sorted_indices]\n",
        "    res_matrix = res_matrix[sorted_indices]\n",
        "\n",
        "    return res_matrix, params"
      ],
      "metadata": {
        "id": "VS9UQF8s4WY2"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal orthogonal matrix composed of eigenvectors\n",
        "def get_optim_matrix(trends: List[np.ndarray], i_matrix_size: Optional[int] = None) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    if i_matrix_size is None:\n",
        "        i_matrix_size = len(trends[0])\n",
        "\n",
        "    # Find covariance matrix\n",
        "    kov = kovariation_matrix(trends, i_matrix_size)\n",
        "\n",
        "    # Find eigenvectors of symmetric matrix\n",
        "    return get_optim_matrix_by_kov(kov, i_matrix_size)"
      ],
      "metadata": {
        "id": "sVp95Vh63pcg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class representing probability density function of random variable\n",
        "class DensityProbFunc:\n",
        "\n",
        "    class DataCont:\n",
        "        def __init__(self):\n",
        "            self.count = 0\n",
        "            self.avg = 0\n",
        "            self.min = float('inf')\n",
        "            self.max = float('-inf')\n",
        "            self.value_p = 0\n",
        "\n",
        "    def __init__(self, p_trend: np.ndarray, i_max_amount_distribution_points: int = 100,\n",
        "                 d_min_value: Optional[float] = None, d_max_value: Optional[float] = None):\n",
        "        self.d_area_min = d_min_value if d_min_value is not None else np.min(p_trend)\n",
        "        self.d_area_max = d_max_value if d_max_value is not None else np.max(p_trend)\n",
        "        self.m_distribution = {}\n",
        "\n",
        "        self.create_density(p_trend, i_max_amount_distribution_points, d_min_value, d_max_value)\n",
        "\n",
        "    def create_density(self, p_trend: np.ndarray, i_max_amount_distribution_points: int = 100,\n",
        "                      d_min_value: Optional[float] = None, d_max_value: Optional[float] = None):\n",
        "        if i_max_amount_distribution_points <= 0:\n",
        "            raise ValueError(\"Invalid number of distribution function ranges\")\n",
        "\n",
        "        self.m_distribution.clear()\n",
        "        self.d_area_min = d_min_value if d_min_value is not None else np.min(p_trend)\n",
        "        self.d_area_max = d_max_value if d_max_value is not None else np.max(p_trend)\n",
        "\n",
        "        d_inc_val = (self.d_area_max - self.d_area_min) / i_max_amount_distribution_points\n",
        "        if d_inc_val == 0:\n",
        "            self.m_distribution[0] = self.DataCont()\n",
        "            self.m_distribution[0].count = len(p_trend)\n",
        "            self.m_distribution[0].avg = self.d_area_min\n",
        "            self.m_distribution[0].min = self.d_area_min\n",
        "            self.m_distribution[0].max = self.d_area_max\n",
        "            self.m_distribution[0].value_p = 1\n",
        "            return\n",
        "\n",
        "        for i_index in range(i_max_amount_distribution_points):\n",
        "            p_data_cont = self.DataCont()\n",
        "            p_data_cont.min = self.d_area_min + (d_inc_val * i_index)\n",
        "            p_data_cont.max = p_data_cont.min + d_inc_val\n",
        "            self.m_distribution[i_index] = p_data_cont\n",
        "\n",
        "        for d_value in p_trend:\n",
        "            i_index = int((d_value - self.d_area_min) / d_inc_val)\n",
        "            if i_index < 0 or i_index >= i_max_amount_distribution_points:\n",
        "                continue\n",
        "            p_data_cont = self.m_distribution[i_index]\n",
        "            p_data_cont.avg += d_value\n",
        "            p_data_cont.count += 1\n",
        "\n",
        "        # Set values for non-zero clusters\n",
        "        for i_index in range(i_max_amount_distribution_points):\n",
        "            p_data_cont = self.m_distribution.get(i_index)\n",
        "            if p_data_cont is None or p_data_cont.count == 0:\n",
        "                continue\n",
        "            p_data_cont.avg /= p_data_cont.count\n",
        "            p_data_cont.value_p = p_data_cont.count / len(p_trend)\n",
        "\n",
        "    # Get probability density value\n",
        "    def get_density_value(self, d_trend_val: float) -> float:\n",
        "        if not self.m_distribution:\n",
        "            return 0\n",
        "\n",
        "        d_inc_val = (self.d_area_max - self.d_area_min) / len(self.m_distribution)\n",
        "        if d_inc_val == 0:\n",
        "            d_inc_val = float('inf')\n",
        "\n",
        "        i_index = int((d_trend_val - self.d_area_min) / d_inc_val)\n",
        "        if i_index < 0 or i_index >= len(self.m_distribution):\n",
        "            return 0\n",
        "\n",
        "        return self.m_distribution.get(i_index, self.DataCont()).value_p"
      ],
      "metadata": {
        "id": "mXji80gW6oXh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a plane based on target and feature data\n",
        "class GMDH:\n",
        "\n",
        "    def __init__(self):\n",
        "        self.m_mgua_k = None\n",
        "        self.m_mgua_max_context = 0\n",
        "        self.m_mgua_max_order = 0\n",
        "        self.m_mgua_total_arg_numb = 0\n",
        "        self.m_mgua_is_const_used = True\n",
        "\n",
        "    # Create model from linear vector\n",
        "    def create_from_linear_vector(self, p_vector_data: np.ndarray, i_max_context: int = 0,\n",
        "                                is_const_used: bool = False, d_const_val: float = 0):\n",
        "        # Save context size\n",
        "        if i_max_context <= 0:\n",
        "            i_max_context = len(p_vector_data)\n",
        "        self.m_mgua_max_context = i_max_context\n",
        "\n",
        "        # Save model order\n",
        "        self.m_mgua_max_order = 1\n",
        "\n",
        "        # Save use of constant offset\n",
        "        self.m_mgua_is_const_used = is_const_used\n",
        "\n",
        "        # Determine number of model arguments\n",
        "        i_offset = 1 if self.m_mgua_is_const_used else 0\n",
        "        self.m_mgua_total_arg_numb = self.m_mgua_max_context + i_offset\n",
        "\n",
        "        # Create vector and copy data to it\n",
        "        self.m_mgua_k = np.zeros(self.m_mgua_total_arg_numb)\n",
        "        for i in range(self.m_mgua_max_context):\n",
        "            self.m_mgua_k[i + i_offset] = p_vector_data[i]\n",
        "        if self.m_mgua_is_const_used:\n",
        "            self.m_mgua_k[0] = d_const_val\n",
        "\n",
        "    # Group method of data handling with order up to maximum\n",
        "    def create_model(self, vals: np.ndarray, trend: np.ndarray, i_max_context: int,\n",
        "                    i_max_order: int, i_target_position: int = 0, i_start_position: int = 0,\n",
        "                    is_const_used: bool = True) -> bool:\n",
        "        # Save context size\n",
        "        self.m_mgua_max_context = i_max_context\n",
        "        if self.m_mgua_max_context < 2:\n",
        "            return False\n",
        "\n",
        "        # Save model order\n",
        "        self.m_mgua_max_order = i_max_order\n",
        "        if self.m_mgua_max_order < 1:\n",
        "            return False\n",
        "\n",
        "        # Save use of constant offset\n",
        "        self.m_mgua_is_const_used = is_const_used\n",
        "\n",
        "        # If end index is not set, take whole sample length\n",
        "        if i_target_position <= 0:\n",
        "            i_target_position = len(vals)\n",
        "\n",
        "        # Determine number of model arguments\n",
        "        self.m_mgua_total_arg_numb = self.get_param_numb(i_max_context, self.m_mgua_max_order, is_const_used)\n",
        "\n",
        "        # Create buffers if they haven't been created or their size is less than needed\n",
        "        if self.m_mgua_k is None or len(self.m_mgua_k) < self.m_mgua_total_arg_numb:\n",
        "            self.m_mgua_k = np.zeros(self.m_mgua_total_arg_numb)\n",
        "\n",
        "        # Initialize buffers\n",
        "        a_matrix = np.zeros((self.m_mgua_total_arg_numb, self.m_mgua_total_arg_numb))\n",
        "        b_vector = np.zeros(self.m_mgua_total_arg_numb)\n",
        "\n",
        "        # For all input vectors\n",
        "        for t in range(i_start_position, i_target_position):\n",
        "            # Set input parameter values to vector K\n",
        "            k_vector = np.zeros(self.m_mgua_total_arg_numb)\n",
        "            self.set_param_buf(self.m_mgua_max_context, self.m_mgua_max_order, vals[t], k_vector, is_const_used)\n",
        "\n",
        "            # Value from training vector\n",
        "            d_curr_value = trend[t]\n",
        "\n",
        "            # Update statistics\n",
        "            for i0 in range(self.m_mgua_total_arg_numb):\n",
        "                k_i0 = k_vector[i0]\n",
        "                for i1 in range(i0 + 1):\n",
        "                    a_matrix[i0, i1] += (k_i0 * k_vector[i1])\n",
        "                b_vector[i0] += (k_i0 * d_curr_value)\n",
        "\n",
        "        # Find model coefficients vector using least squares\n",
        "        try:\n",
        "            self.m_mgua_k = np.linalg.lstsq(a_matrix, b_vector, rcond=None)[0]\n",
        "        except np.linalg.LinAlgError:\n",
        "            return False\n",
        "\n",
        "        return (not np.any(np.isnan(self.m_mgua_k))) and (not np.any(np.isinf(self.m_mgua_k))) and (np.sum(np.abs(self.m_mgua_k)) != 0)\n",
        "\n",
        "    #  Calculate predicted value using existing model\n",
        "    def calculate_prognos(self, sample: np.ndarray) -> float:\n",
        "        if self.m_mgua_max_order < 1:\n",
        "            return 0\n",
        "\n",
        "        # Calculate predicted value using found model\n",
        "        k_vector = np.zeros(self.m_mgua_total_arg_numb)\n",
        "        self.set_param_buf(self.m_mgua_max_context, self.m_mgua_max_order, sample, k_vector, self.m_mgua_is_const_used)\n",
        "        return np.dot(k_vector, self.m_mgua_k)\n",
        "\n",
        "    # Return number of variables for given context size\n",
        "    @staticmethod\n",
        "    def get_param_numb(i_max_context: int, i_max_order: int, is_const_used: bool) -> int:\n",
        "        i_count = 1\n",
        "        i_total = 1 if is_const_used else 0  # Account for constant component\n",
        "\n",
        "        for i_curr_order in range(1, i_max_order + 1):\n",
        "            j = i_max_context + i_curr_order - 1\n",
        "            i_count = i_count * j // i_curr_order\n",
        "            i_total += i_count\n",
        "\n",
        "        return i_total\n",
        "\n",
        "    # Set input vector of length i_max_context to vector that is argument for GMDH method\n",
        "    @staticmethod\n",
        "    def set_param_buf(i_max_context: int, i_max_order: int, inp_buf: np.ndarray,\n",
        "                     out_buf: np.ndarray, is_const_used: bool):\n",
        "        i_count = 0\n",
        "\n",
        "        for i_curr_order in range(0 if is_const_used else 1, i_max_order + 1):\n",
        "            i_count = GMDH.order_param_create(i_count, i_curr_order, 0, i_max_context, 1, inp_buf, out_buf)\n",
        "\n",
        "    # Recursive function for setting buffer\n",
        "    @staticmethod\n",
        "    def order_param_create(i_count: int, i_level: int, i_context: int, i_max_context: int,\n",
        "                          d_upper: float, inp_buf: np.ndarray, out_buf: np.ndarray) -> int:\n",
        "        if i_level > 0:\n",
        "            # This function is called recursively\n",
        "            for i_context in range(i_context, i_max_context):\n",
        "                i_count = GMDH.order_param_create(i_count, i_level - 1, i_context, i_max_context,\n",
        "                                                d_upper * inp_buf[i_context], inp_buf, out_buf)\n",
        "        else:\n",
        "            out_buf[i_count] = d_upper\n",
        "            i_count += 1\n",
        "\n",
        "        return i_count"
      ],
      "metadata": {
        "id": "fvxBMnI57H4k"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forming list of normalized trend changes\n",
        "p_delta_filter_trends = {}\n",
        "for tt in range(i_window_size, i_prep_trend_length - i_predict_amount + 1):\n",
        "    p_norm_trend = norming_e(p_trend_mean, tt + i_predict_amount, i_window_size + i_predict_amount,\n",
        "                            0, i_window_size, True)\n",
        "    p_delta_filter_trends[tt] = p_norm_trend[i_window_size] - p_norm_trend[i_window_size - 1]"
      ],
      "metadata": {
        "id": "iagximNf0med"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forming list of normalized trends for all positions\n",
        "p_buffer_trends = {}\n",
        "for tt in range(i_buffer_size, len(p_trend_mean) + 1):\n",
        "    p_buffer = np.concatenate([\n",
        "        norming_e(p_trend_open, tt, i_buffer_size, 0, i_buffer_size, True),\n",
        "        norming_e(p_trend_lo, tt, i_buffer_size, 0, i_buffer_size, True),\n",
        "        norming_e(p_trend_hi, tt, i_buffer_size, 0, i_buffer_size, True),\n",
        "        norming_e(p_trend_close, tt, i_buffer_size, 0, i_buffer_size, True),\n",
        "        norming_e(p_trend_volume, tt, i_buffer_size, 0, i_buffer_size, True),\n",
        "        norming_e(p_trend_value, tt, i_buffer_size, 0, i_buffer_size, True)\n",
        "    ])\n",
        "    if not (np.isinf(p_buffer).any() and not np.isnan(p_buffer).any()):\n",
        "        p_buffer_trends[tt] = p_buffer"
      ],
      "metadata": {
        "id": "KCUinMhK01eZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Forming trend arrays grouped by change value\n",
        "d_delta = (len(p_delta_filter_trends) - (i_buffer_size - i_window_size if i_buffer_size > i_window_size else 0)) / i_ranges_amount\n",
        "if d_delta < 2:\n",
        "    raise ValueError(\"Minimum 2 elements per range required\")\n",
        "\n",
        "i_counter = 0\n",
        "i_zero_index = 0\n",
        "p_ranges_trends = [set() for _ in range(i_ranges_amount)]\n",
        "\n",
        "for tt, val in sorted(p_delta_filter_trends.items(), key=lambda x: x[1]):\n",
        "    if tt not in p_buffer_trends:\n",
        "        continue\n",
        "    i_index = min(int(i_counter / d_delta), i_ranges_amount - 1)\n",
        "    p_ranges_trends[i_index].add(tt)\n",
        "    if val < 0 and i_zero_index < i_index:\n",
        "        i_zero_index = i_index\n",
        "    i_counter += 1\n",
        "\n",
        "# Refine zero position\n",
        "i_pos_count = sum(1 for tt in p_ranges_trends[i_zero_index] if p_delta_filter_trends[tt] > 0)\n",
        "i_neg_count = sum(1 for tt in p_ranges_trends[i_zero_index] if p_delta_filter_trends[tt] < 0)\n",
        "d_zero_value = i_neg_count / (i_neg_count + i_pos_count) if (i_neg_count + i_pos_count) > 0 else 0.5"
      ],
      "metadata": {
        "id": "7VGLlnE11jzG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Orthogonal matrices for ranges\n",
        "p_ort_matrix = [None] * i_ranges_amount\n",
        "p_eigen_vals = [None] * i_ranges_amount\n",
        "p_range_models = [None] * i_ranges_amount\n",
        "p_models_distrib_funcs = [None] * i_ranges_amount\n",
        "\n",
        "for i_index1 in range(i_ranges_amount):\n",
        "    # Form orthogonal matrix\n",
        "    p_curr_data_set_src = [p_buffer_trends[tt] for tt in p_ranges_trends[i_index1]]\n",
        "    if not p_curr_data_set_src:\n",
        "        continue\n",
        "\n",
        "    # Calculate optimal orthogonal matrix\n",
        "    p_ort_matrix[i_index1], p_eigen_vals[i_index1] = get_optim_matrix(p_curr_data_set_src)\n",
        "\n",
        "    # Recalculate for entire buffer\n",
        "    p_buffer_trends2 = {}\n",
        "    for tt, values in p_buffer_trends.items():\n",
        "        p_matrix_spektr = np.zeros(len(values) - i_amount_excluded)\n",
        "        for w in range(len(p_matrix_spektr)):\n",
        "            d_val = np.dot(p_ort_matrix[i_index1][w], values[:len(p_ort_matrix[i_index1][w])])\n",
        "            p_matrix_spektr[w] = d_val\n",
        "        p_buffer_trends2[tt] = p_matrix_spektr\n",
        "\n",
        "    # Add to list of unit orthogonal functions planes\n",
        "    p_models_curr = []\n",
        "    p_base_vector = np.zeros(len(p_buffer_trends2[next(iter(p_buffer_trends2))]))\n",
        "\n",
        "    for w in range(len(p_base_vector)):\n",
        "        p_base_vector[w] = 1\n",
        "        p_ort_matrix_model = GMDH()\n",
        "        p_ort_matrix_model.create_from_linear_vector(p_base_vector, len(p_base_vector))\n",
        "        p_models_curr.append(p_ort_matrix_model)\n",
        "        p_base_vector[w] = 0\n",
        "\n",
        "    # Forming mutual range boundary models\n",
        "    p_curr_data_set1 = [p_buffer_trends2[tt] for tt in p_ranges_trends[i_index1]]\n",
        "    if not p_curr_data_set1:\n",
        "        continue\n",
        "\n",
        "    for i_index2 in range(i_ranges_amount):\n",
        "        if i_index2 == i_index1:\n",
        "            continue\n",
        "\n",
        "        p_curr_data_set2 = [p_buffer_trends2[tt] for tt in p_ranges_trends[i_index2]]\n",
        "        if not p_curr_data_set2:\n",
        "            continue\n",
        "\n",
        "        # Calculate GMDH model\n",
        "        p_curr_model = GMDH()\n",
        "        p_src_list = np.array(p_curr_data_set1 + p_curr_data_set2)\n",
        "        p_dst_list = np.array([1.0] * len(p_curr_data_set1) + [-1.0] * len(p_curr_data_set2))\n",
        "        if p_curr_model.create_model(p_src_list, p_dst_list, len(p_src_list[0]), i_polinom_order_model,\n",
        "                                  len(p_src_list), 0, b_is_using_const_model):\n",
        "            p_models_curr.append(p_curr_model)\n",
        "\n",
        "    p_range_models[i_index1] = p_models_curr\n",
        "\n",
        "    # Calculate probability densities for mutual GMDH range boundary models\n",
        "    p_curr_distrib_funcs = []\n",
        "    for w in range(len(p_models_curr)):\n",
        "        p_matrix_spektr = np.array([p_models_curr[w].calculate_prognos(sample) for sample in p_curr_data_set1])\n",
        "        d_e = np.mean(p_matrix_spektr)\n",
        "        d_ee = np.mean(p_matrix_spektr ** 2)\n",
        "        d_sigma = np.sqrt(d_ee - (d_e * d_e))\n",
        "        p_min_value = max(d_e - (d_rmse_koef * d_sigma), np.min(p_matrix_spektr))\n",
        "        p_max_value = min(d_e + (d_rmse_koef * d_sigma), np.max(p_matrix_spektr))\n",
        "        p_curr_distrib_funcs.append(DensityProbFunc(p_matrix_spektr, i_density_amount,\n",
        "                                                    p_min_value, p_max_value))\n",
        "    p_models_distrib_funcs[i_index1] = p_curr_distrib_funcs"
      ],
      "metadata": {
        "id": "U4HSltpw2ErM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculation considering distribution function\n",
        "p_buffer_trends_out = {}\n",
        "for tt, values in p_buffer_trends.items():\n",
        "    d_sum_vals = 0\n",
        "    p_result = np.zeros(i_ranges_amount)\n",
        "\n",
        "    for i_index in range(i_ranges_amount):\n",
        "        d_val = 0\n",
        "        # Recalculate buffer by optimal orthogonal matrix for range\n",
        "        if p_ort_matrix[i_index] is None:\n",
        "            continue\n",
        "\n",
        "        p_buf_curr = np.zeros(len(values) - i_amount_excluded)\n",
        "        for w in range(len(p_buf_curr)):\n",
        "            p_buf_curr[w] = np.dot(p_ort_matrix[i_index][w], values[:len(p_ort_matrix[i_index][w])])\n",
        "\n",
        "        # Calculate probabilities of divergence by mutual range boundary models vectors\n",
        "        p_models_curr = p_range_models[i_index]\n",
        "        if p_models_curr is not None:\n",
        "            p_curr_distrib_funcs = p_models_distrib_funcs[i_index]\n",
        "            for w in range(len(p_curr_distrib_funcs)):\n",
        "                d_sp = p_models_curr[w].calculate_prognos(p_buf_curr)\n",
        "                d_sp = p_curr_distrib_funcs[w].get_density_value(d_sp)\n",
        "                if d_sp == 0:\n",
        "                    d_sp = d_probably_min\n",
        "                d_val += np.log(d_sp)\n",
        "        #d_val = np.exp(d_val)\n",
        "        d_val = d_order_softmax_out ** d_val  # Softmax\n",
        "        d_sum_vals += d_val\n",
        "        p_result[i_index] = d_val\n",
        "\n",
        "    p_result /= d_sum_vals\n",
        "    p_buffer_trends_out[tt] = p_result"
      ],
      "metadata": {
        "id": "Ql655RsA8ZnG"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recalculation of output buffer trends\n",
        "p_out_result_trends = {}\n",
        "for tt, values in p_buffer_trends_out.items():\n",
        "    d_probs0 = np.sum(values[:i_zero_index]) + d_zero_value * values[i_zero_index]\n",
        "    d_probs1 = np.sum(values[i_zero_index+1:]) + (1.0 - d_zero_value) * values[i_zero_index]\n",
        "    p_out_result_trends[tt] = (d_probs1 - d_probs0) / (d_probs0 + d_probs1)"
      ],
      "metadata": {
        "id": "lJ_SNO8Y8o90"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_less_than_0 = sum(1 for value in p_out_result_trends.values() if value < 0)\n",
        "count_great_than_0 = sum(1 for value in p_out_result_trends.values() if value > 0)\n",
        "count_not_value = sum(1 for value in p_out_result_trends.values() if np.isnan(value) or np.isinf(value))\n",
        "print(f\"Количество элементов меньше 0: {count_less_than_0}\")\n",
        "print(f\"Количество элементов больше 0: {count_great_than_0}\")\n",
        "print(f\"Количество элементов не чисел: {count_not_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPZxQRB_BKOQ",
        "outputId": "baf5eb22-f7b2-492a-e0cd-5aa85176912a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество элементов меньше 0: 2936\n",
            "Количество элементов больше 0: 3123\n",
            "Количество элементов не чисел: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(p_models_distrib_funcs[4])\n",
        "#len(p_out_result_trends)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6FNAHWKKl-v",
        "outputId": "05ff89f3-b3d1-48b8-ea52-e6efc061f526"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ************* Trading simulation on historical data *************\n",
        "# Создание стратегии для backtrader на основе Ensemble\n",
        "class SimulationStrategyEnsemble(bt.Strategy):\n",
        "    def __init__(self):\n",
        "        self.prediction_index = 0  # Индекс для отслеживания текущего предсказания\n",
        "\n",
        "    def next(self):\n",
        "        if self.prediction_index < len(p_buffer_trends_out):\n",
        "            prediction = p_buffer_trends_out[self.prediction_index]\n",
        "            if prediction > 0:  # Если предсказание роста цены\n",
        "                if not self.position:\n",
        "                    self.buy()  # Открываем длинную позицию\n",
        "            elif prediction < 0:  # Если предсказание падения цены\n",
        "                if self.position:\n",
        "                    self.sell()  # Закрываем позицию\n",
        "            self.prediction_index += 1"
      ],
      "metadata": {
        "id": "yt18ZW_rQpz-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Backtrader strategy implementation\n",
        "class BacktestStrategy(bt.Strategy):\n",
        "    params = (\n",
        "        ('out_result_trends', p_out_result_trends),\n",
        "        ('prep_trend_length', i_prep_trend_length),\n",
        "        ('zero_zone_koef', d_zero_zone_koef),\n",
        "        ('trend_koef_up', d_trend_koef_up),\n",
        "        ('trend_koef_dn', d_trend_koef_dn),\n",
        "        ('dither_koef', d_dither_koef),\n",
        "        ('is_short_enabled', b_is_short_enabled)\n",
        "    )\n",
        "\n",
        "    def __init__(self):\n",
        "        self.extreme_price_min = self.data.close[0]\n",
        "        self.extreme_price_max = self.data.close[0]\n",
        "        self.avg_index_prev = 0\n",
        "        self.order = None\n",
        "        self.money_count_trend = []\n",
        "\n",
        "    def next(self):\n",
        "        current_idx = len(self.data) - 1\n",
        "        t = current_idx + self.p.prep_trend_length\n",
        "\n",
        "        if t not in self.p.out_result_trends:\n",
        "            return\n",
        "\n",
        "        # Get complex indicator value for this position\n",
        "        d_avg_index = self.p.out_result_trends[t]\n",
        "\n",
        "        # Exponential smoothing\n",
        "        if self.avg_index_prev != 0:\n",
        "            d_avg_index = (self.p.dither_koef * d_avg_index) + (1 - self.p.dither_koef) * self.avg_index_prev\n",
        "        self.avg_index_prev = d_avg_index\n",
        "\n",
        "        # Check if in cash (no stocks)\n",
        "        if abs(self.position.size) <= 1e-10:\n",
        "            # Check for Long entry\n",
        "            d_th_price = self.extreme_price_min * (1.0 + self.p.trend_koef_up)\n",
        "            if (d_th_price <= self.data.high[0]) and (d_avg_index > self.p.zero_zone_koef):\n",
        "                if d_th_price < self.data.open[0]:\n",
        "                    d_th_price = self.data.open[0]\n",
        "                # Need to buy\n",
        "                self.order = self.buy(price=d_th_price)\n",
        "                self.extreme_price_max = self.extreme_price_min = d_th_price\n",
        "            elif self.p.is_short_enabled:\n",
        "                # Check for Short entry\n",
        "                d_th_price = self.extreme_price_max * (1.0 - self.p.trend_koef_dn)\n",
        "                if (self.data.low[0] <= d_th_price) and (d_avg_index < -self.p.zero_zone_koef):\n",
        "                    if d_th_price > self.data.open[0]:\n",
        "                        d_th_price = self.data.open[0]\n",
        "                    # Need to sell\n",
        "                    self.order = self.sell(price=d_th_price)\n",
        "                    self.extreme_price_min = self.extreme_price_max = d_th_price\n",
        "\n",
        "        # In Long position\n",
        "        elif self.position.size > 0:\n",
        "            # Check for exit to Cash\n",
        "            d_th_price = self.extreme_price_max * (1.0 - self.p.trend_koef_dn)\n",
        "            if (self.data.low[0] <= d_th_price) and (d_avg_index < -self.p.zero_zone_koef):\n",
        "                if d_th_price > self.data.open[0]:\n",
        "                    d_th_price = self.data.open[0]\n",
        "                # Need to sell\n",
        "                self.order = self.close(price=d_th_price)\n",
        "                self.extreme_price_min = self.extreme_price_max = d_th_price\n",
        "\n",
        "        # In Short position\n",
        "        elif self.position.size < 0:\n",
        "            # Check for exit to Cash\n",
        "            d_th_price = self.extreme_price_min * (1.0 + self.p.trend_koef_up)\n",
        "            if (d_th_price <= self.data.high[0]) and (d_avg_index > self.p.zero_zone_koef):\n",
        "                if d_th_price < self.data.open[0]:\n",
        "                    d_th_price = self.data.open[0]\n",
        "                self.order = self.close(price=d_th_price)\n",
        "                self.extreme_price_max = self.extreme_price_min = d_th_price\n",
        "\n",
        "        # Search for minimum for position entry\n",
        "        self.extreme_price_min = min(self.extreme_price_min, self.data.low[0])\n",
        "        # Search for maximum for position entry\n",
        "        self.extreme_price_max = max(self.extreme_price_max, self.data.high[0])\n",
        "\n",
        "        # Save portfolio value\n",
        "        self.money_count_trend.append(self.broker.getvalue())\n",
        "\n",
        "    def stop(self):\n",
        "        # Final portfolio value\n",
        "        self.money_count_trend.append(self.broker.getvalue())\n",
        "\n",
        "        # Output results\n",
        "        print(f\"Maximum result value = {self.broker.getvalue()}\")\n",
        "        print(f\"Optimal data window size = {i_window_size}\")\n",
        "        print(f\"Optimal prediction count = {i_predict_amount}\")\n",
        "        print(f\"Optimal buffer window size = {i_buffer_size}\")\n",
        "        print(f\"Optimal range count = {i_ranges_amount}\")\n",
        "        print(f\"Optimal probability density intervals = {i_density_amount}\")\n",
        "        print(f\"Optimal smoothing coefficient = {d_dither_koef}\")\n",
        "        print(f\"Optimal Up trade cutoff coefficient = {d_trend_koef_up}\")\n",
        "        print(f\"Optimal Dn trade cutoff coefficient = {d_trend_koef_dn}\")\n",
        "        print(f\"Optimal 'zero zone' coefficient = {d_zero_zone_koef}\")\n",
        "\n",
        "        # Plot results\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(self.money_count_trend)\n",
        "        plt.title(\"Portfolio Value Over Time\")\n",
        "        plt.xlabel(\"Time\")\n",
        "        plt.ylabel(\"Portfolio Value\")\n",
        "\n",
        "        # Save plot\n",
        "        output_dir = \"results\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        output_file = os.path.join(output_dir,\n",
        "            f\"{s_ticker}_Result={self.broker.getvalue():.5f}_WndSize={i_window_size}_Predict={i_predict_amount}.png\")\n",
        "        plt.savefig(output_file)\n",
        "        plt.close()"
      ],
      "metadata": {
        "id": "yMLaA1fz9FR9"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create cerebro engine\n",
        "cerebro = bt.Cerebro()\n",
        "\n",
        "# Add strategy\n",
        "#cerebro.addstrategy(BacktestStrategy)\n",
        "cerebro.addstrategy(SimulationStrategyEnsemble)\n",
        "\n",
        "# Prepare data feed\n",
        "test_data = data.iloc[-i_test_trend_size:]  # Выбираем тестовую часть данных\n",
        "test_data = bt.feeds.PandasData(dataname=test_data)\n",
        "cerebro.adddata(test_data)\n",
        "\n",
        "# Add analyzers\n",
        "cerebro.addanalyzer(bt.analyzers.TradeAnalyzer, _name=\"ta\")\n",
        "cerebro.addanalyzer(bt.analyzers.SharpeRatio, _name=\"sharpe\", timeframe=bt.TimeFrame.Days)\n",
        "cerebro.addanalyzer(bt.analyzers.DrawDown, _name=\"drawdown\")\n",
        "cerebro.addanalyzer(bt.analyzers.Returns, _name=\"returns\")\n",
        "cerebro.addanalyzer(bt.analyzers.PyFolio, _name=\"pyfolio\")\n",
        "cerebro.addanalyzer(bt.analyzers.TimeReturn, _name='timereturn')\n",
        "\n",
        "# Set initial capital\n",
        "cerebro.broker.setcash(i_start_capital)\n",
        "\n",
        "# Set commission\n",
        "cerebro.broker.setcommission(commission=d_trader_marging)\n",
        "\n",
        "# Run backtest\n",
        "print('Starting Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
        "cerebro.run()\n",
        "print('Final Portfolio Value: %.2f' % cerebro.broker.getvalue())\n",
        "\n",
        "# Plot results if needed\n",
        "# cerebro.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "F2W-_Rhk9dTs",
        "outputId": "e3bde279-326e-4fc3-982c-9f6b4b4467ea"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Portfolio Value: 1.00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/backtrader/feeds/pandafeed.py:268: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
            "  dt = tstamp.to_pydatetime()\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-dbb04b2122b8>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Run backtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Starting Portfolio Value: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Final Portfolio Value: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcerebro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;31m# let's skip process \"spawning\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0miterstrat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterstrats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m                 \u001b[0mrunstrat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunstrategies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterstrat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dooptimize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36mrunstrategies\u001b[0;34m(self, iterstrat, predata)\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runonce_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runonce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrunstrats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moldsync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backtrader/cerebro.py\u001b[0m in \u001b[0;36m_runonce\u001b[0;34m(self, runstrats)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1699\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstrat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrunstrats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1700\u001b[0;31m                 \u001b[0mstrat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_oncepost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1701\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_stop\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# stop if requested\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m                     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backtrader/strategy.py\u001b[0m in \u001b[0;36m_oncepost\u001b[0;34m(self, dt)\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mminperstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnextstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# only called for the 1st value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprenext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/backtrader/lineiterator.py\u001b[0m in \u001b[0;36mnextstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# Called once for 1st full calculation - defaults to regular next\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-c46553a2b81a>\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_index\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_buffer_trends_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_buffer_trends_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Если предсказание роста цены\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}